{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Atenção: este notebook foi desenhado para funcionar no **Google Collab**. Se pretende executar localmente prefira a versão local deste notebook, sem o sufixo ```-collab```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requerimentos\n",
    "\n",
    "Todas as bibliotecas já estão instaladas no Google Colab.\n",
    "\n",
    "* OpenCV >= 3.4.3\n",
    "* Matplotlib >= 3.1.3\n",
    "* Seaborn >= 0.0.10\n",
    "* Numpy >= 1.18.1\n",
    "\n",
    "### 1.2 Arquivos\n",
    "\n",
    "Baixe o repositório do GitHub utilizando o comando abaixo. Em caso de atualização, utilize o comando para apagar o diretório antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf fiap-ml-visao-computacional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/michelpf/fiap-ml-visao-computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora posicionar o diretório do repositório para a aula respectiva. Nesse caso envie o comando de mudança de diretório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd fiap-ml-visao-computacional/aula-3-segmentacao/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das biblitecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "#Exibição na mesma tela do Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Suavização de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A suavização de imagens (ou Blurring) auxilia no processo de remoção de ruídos e diminuição de detalhes de uma imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retangulo = np.zeros((200,200), np.uint8)\n",
    "cv2.rectangle(retangulo, (40,40), (160,160), 255, -2)\n",
    "\n",
    "imagem_suav_padrao = cv2.blur(retangulo, (15,15))\n",
    "imagem_suav_mediana = cv2.medianBlur(retangulo, 15)\n",
    "imagem_suav_gaussian = cv2.GaussianBlur(retangulo, (15, 15), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(retangulo, cmap=\"gray\")\n",
    "plt.title(\"Retangulo\")\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem_suav_padrao, cmap=\"gray\")\n",
    "plt.title(\"Média\")\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem_suav_mediana, cmap=\"gray\")\n",
    "plt.title(\"Mediana\")\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem_suav_gaussian, cmap=\"gray\")\n",
    "plt.title(\"Gaussiana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/tesla.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem)\n",
    "plt.title(\"Carro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_suav_padrao = cv2.blur(imagem, (15,15))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem_suav_padrao)\n",
    "plt.title(\"Suavização Média\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_suav_mediana = cv2.medianBlur(imagem, 15)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem_suav_mediana)\n",
    "plt.title(\"Suavização Mediana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_suav_gaussian = cv2.GaussianBlur(imagem, (15, 15), 0)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem_suav_gaussian)\n",
    "plt.title(\"Suavização Gaussiana\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para adicionar ruído do tipo _pepper & salt_. \n",
    "Algoritmo obtido neste [post](https://stackoverflow.com/questions/22937589/how-to-add-noise-gaussian-salt-and-pepper-etc-to-image-in-python-with-opencv), no Stackoverflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_noise(image, prob):\n",
    "    output = np.zeros(image.shape,np.uint8)\n",
    "    thres = 1 - prob \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            rdn = random.random()\n",
    "            if rdn < prob:\n",
    "                output[i][j] = 0\n",
    "            elif rdn > thres:\n",
    "                output[i][j] = 255\n",
    "            else:\n",
    "                output[i][j] = image[i][j]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_tesla = cv2.imread(\"imagens/tesla-x.jpg\")\n",
    "imagem_tesla = cv2.cvtColor(imagem_tesla, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "imagem_ruido = sp_noise(imagem_tesla, 0.05)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem_ruido)\n",
    "plt.title(\"Imagem com ruído\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_suav_padrao = cv2.blur(imagem_ruido, (15,15))\n",
    "imagem_suav_mediana = cv2.medianBlur(imagem_ruido, 15)\n",
    "imagem_suav_gaussian = cv2.GaussianBlur(imagem_ruido, (15, 15), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem_suav_padrao)\n",
    "plt.title(\"Suavização Média\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem_suav_mediana)\n",
    "plt.title(\"Suavização Mediana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imagem_suav_gaussian)\n",
    "plt.title(\"Suavização Gaussiana\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Thresholding (Limiarização)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Técnicas de filtragem na imagem para remover ruídos ou regiões de interesse baseado no limiar de intensidade dos pixels.\n",
    "Somente é permitido imagems em escala de cinza.\n",
    "\n",
    "*Adaptado desta [documentação](https://docs.opencv.org/3.4.3/d7/d4d/tutorial_py_thresholding.html) do OpenCV*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/car.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Imagem Original\")\n",
    "plt.imshow(imagem, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, imagem_limiarizada = cv2.threshold(imagem, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(imagem_limiarizada, cmap=\"gray\")\n",
    "plt.title(\"Limiarização binária\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, imagem_limiarizada = cv2.threshold(imagem, 190, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Limiarização binária invertida\")\n",
    "plt.imshow(imagem_limiarizada, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, imagem_limiarizada = cv2.threshold(imagem, 50, 255, cv2.THRESH_TRUNC)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Limiarização por truncagem\")\n",
    "plt.imshow(imagem_limiarizada, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, imagem_limiarizada = cv2.threshold(imagem, 150, 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Limiarização para zero\")\n",
    "plt.imshow(imagem_limiarizada, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, imagem_limiarizada = cv2.threshold(imagem, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Limiarização para zero invertido\")\n",
    "plt.imshow(imagem_limiarizada, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Limiar adaptativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tipo de limiar é mais suave e obtem melhores resultados particularmente em operações voltadas a documentos para etapas de OCR. \n",
    "A característica de adaptividade permite que o efeito do limiar leve em consideração aspectos internos da imagem e não seja penas um filtro que ignora toda informação em função dos limiares configurados.\n",
    "\n",
    "*Adaptado desta [documentação](https://docs.opencv.org/3.4.3/d7/d4d/tutorial_py_thresholding.html) do OpenCV.*\n",
    "*Imagem retirada deste [post](https://pythonprogramming.net/thresholding-image-analysis-python-opencv-tutorial/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/bookpage.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(imagem, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, imagem_limiarizada = cv2.threshold(imagem, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.title(\"Limiarização\")\n",
    "plt.imshow(imagem_limiarizada, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_suavizada = cv2.GaussianBlur(imagem, (5,5), 0)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.title(\"Suavização\")\n",
    "plt.imshow(imagem_suavizada, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, imagem_limiarizada = cv2.threshold(imagem_suavizada, 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.title(\"Limiarização após Suavização\")\n",
    "plt.imshow(imagem_limiarizada, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_limiarizada = cv2.adaptiveThreshold(imagem_suavizada, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 101, 2)\n",
    "\n",
    "# O primeiro valor do parâmetro é o tamanho da janela, portanto sempre ímpar para considerar o valor do contro\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.title(\"Limiarização com Limiar Adaptativo\")\n",
    "plt.imshow(imagem_limiarizada, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Erosão e Dilatação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "São operações morfológicas que visam restarurar informação na imagem aplicando operações que podem, por exemplo, completar pixels adjacentes ou removê-los.\n",
    "\n",
    "Quando trabalhamos com OCR em imagens obtidas de scanners ou placas de veículos de automóveis, dada a qualidade da captura destas imagens nem sempre é preservad a informação com mesma nitidez o suficiente para algoritmos de OCR (como o _Tesseract_) identificarem os carcteres adequadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/parking-lot.jpg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.title(\"Faixas\")\n",
    "plt.imshow(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_gray = cv2.imread(\"imagens/parking-lot.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.title(\"Faixas\")\n",
    "plt.imshow(imagem_gray, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_suavizada = cv2.GaussianBlur(imagem_gray, (1,1), 0)\n",
    "ret, imagem_limiarizada = cv2.threshold(imagem_suavizada, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.title(\"Limiarização após Suavização\")\n",
    "plt.imshow(imagem_limiarizada, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3), np.uint8)\n",
    "imagem_dilatacao = cv2.dilate(imagem_limiarizada, kernel, iterations=2)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.title(\"Dilatação\")\n",
    "plt.imshow(imagem_dilatacao, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((1,1), np.uint8)\n",
    "imagem_erosao = cv2.erode(imagem_limiarizada, kernel, iterations=1)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.title(\"Erosão\")\n",
    "plt.imshow(imagem_erosao, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detecção de bordas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os operações de detecção de bordas é o primeiro passo para segmentação de imagens, pois torna possível identificar objetos.\n",
    "Existem diversas formas de detectar bordas, das quais a que mais se destaca é o método de Canny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_gray = cv2.imread(\"imagens/woman.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Mulher\")\n",
    "plt.imshow(imagem_gray, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Método Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borda_canny = cv2.Canny(imagem_gray, 40, 80)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Bordas\")\n",
    "plt.imshow(borda_canny, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " _, mask = cv2.threshold(borda_canny, 30, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Bordas\")\n",
    "plt.imshow(mask, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Segmentação de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Técnicas para identificação de objetos e formas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Contornos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo para identificar contornos de objetos em imagens é aplicando operações de identificação de contornos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_objetos = cv2.imread(\"imagens/formas.jpeg\")\n",
    "imagem_objetos = cv2.cvtColor(imagem_objetos, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(imagem_objetos.shape)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Objetos\")\n",
    "plt.imshow(imagem_objetos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_objetos_gray = cv2.cvtColor(imagem_objetos,cv2.COLOR_BGR2GRAY)\n",
    "imagem_objetos_bordas = cv2.Canny(imagem_objetos_gray, 1, 100)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Bordas\")\n",
    "plt.imshow(imagem_objetos_bordas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contornos_objetos, hierarchy_objetos = cv2.findContours(imagem_objetos_bordas, \n",
    "                                                           cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(\"Contornos encontrados \"+str(len(contornos_objetos)))\n",
    "\n",
    "imagem_objetos_contornos = imagem_objetos.copy()\n",
    "cv2.drawContours(imagem_objetos_contornos, contornos_objetos, -1, (0,255,0), 3)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Contornos\")\n",
    "plt.imshow(imagem_objetos_contornos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando formas abertas da mesma imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contornos_objetos_internos, hierarchy = cv2.findContours(imagem_objetos_bordas, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(\"Contornos encontrados \"+str(len(contornos_objetos_internos)))\n",
    "\n",
    "for idx, contorno in enumerate(contornos_objetos_internos):\n",
    "    (x, y, w, h) = cv2.boundingRect(contorno)\n",
    "    area = int(w) * int(h)\n",
    "    print(\"Contorno \" + str(idx) + \" \" + str(area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_contornos_internos = imagem_objetos.copy()\n",
    "cv2.drawContours(imagem_contornos_internos, contornos_objetos_internos, -1, (0,255,0), 2)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Contornos\")\n",
    "plt.imshow(imagem_contornos_internos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os contornos adicionais encontrados são referentes a possíveis ruídos na imagem e na forma que os contornos são identificados. Há formas de conhecer melhor cada contorno e verificar se pode ser desconsiderado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Ordenando Contornos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como foi mostrado anteriormente, podemos trabalhar com as informações de contorno para determinar aspectos como área e posição que auxiliam no processo de remoção de ruídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/objects.png\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(imagem.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_gray = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "imagem_gray_suav = cv2.GaussianBlur(imagem_gray, (3,3), 0)\n",
    "imagem_bordas = cv2.Canny(imagem_gray_suav, 40, 180)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Contornos\")\n",
    "plt.imshow(imagem_bordas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contornos_formas, hierarchy = cv2.findContours(imagem_bordas, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(\"Contornos encontrados \"+str(len(contornos_formas)))\n",
    "\n",
    "imagem_contornos = imagem.copy()\n",
    "\n",
    "cv2.drawContours(imagem_contornos, contornos_formas, -1, (0,255,0), 2)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Contornos\")\n",
    "plt.imshow(imagem_contornos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areas_contornos(contornos):\n",
    "    areas = []\n",
    "    for contorno in contornos:\n",
    "        area = cv2.contourArea(contorno)\n",
    "        areas.append(area)\n",
    "    return areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_contornos(contornos_formas), len(areas_contornos(contornos_formas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas vezes, certas imagens podem apresentar pequenos contornos (com áreas entre 0 e 0,5, por exemplo) que são considerados ruídos. Neste caso podemos fazer uma limpeza nestes contornos para eliminar estes ruídos.\n",
    "Para este exemplo vamos arbitrar que somente áreas maiores do que 1 sejam consideradas.\n",
    "\n",
    "_Neste exemplo não houve nenhum ruído_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_contornos(contornos_formas)\n",
    "contornos_padronizados = []\n",
    "\n",
    "for contorno in contornos_formas:\n",
    "    if cv2.contourArea(contorno) > 1:\n",
    "        contornos_padronizados.append(contorno)\n",
    "    \n",
    "len(contornos_formas), len(contornos_padronizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na análise visual, agora o número de contornos identificados batem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir vai localizar o centróide de cada objeto na imagem para colocarmos um determinado texto. Este texto utilizaremos para identificar as imagens por tamanho de área e por posicionamento, as seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_centroide(imagem, contorno, identificacao):\n",
    "    M = cv2.moments(contorno)\n",
    "    cx = int(M[\"m10\"]/M[\"m00\"])\n",
    "    cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "    cv2.putText(imagem, str(identificacao), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenação decrescente baseado no tamanho da área. A função *sorted* irá analisar todos os itens do array de contornos, aplicar a função de cálculo de área e ordederá de forma reversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contornos_ordenacao = sorted(contornos_padronizados, key=cv2.contourArea, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contornos_ordenacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_contornos = imagem.copy()\n",
    "\n",
    "for idx, contorno in enumerate(contornos_ordenacao):\n",
    "    area = cv2.contourArea(contorno)\n",
    "    label_centroide(imagem_contornos, contorno, idx+1)\n",
    "    print(\"Processando contorno \" + str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Contornos Ordenados Área\")\n",
    "plt.imshow(imagem_contornos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenação por posicionamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir obterá a coordenada X de cada contorno, assim será possível ordenar as imagens por esta coordenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posicao_x(contorno):\n",
    "    M = cv2.moments(contorno)\n",
    "    cx = int(M[\"m10\"]/M[\"m00\"])\n",
    "    return cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "contornos_ordenados_x = sorted(contornos_padronizados, key=posicao_x, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_contornos = imagem.copy()\n",
    "\n",
    "for idx, contorno in enumerate(contornos_ordenados_x):\n",
    "    label_centroide(imagem_contornos, contorno, idx+1)\n",
    "    \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Contornos Ordenados X\")\n",
    "plt.imshow(imagem_contornos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Aproximação de contornos e *convex hull* (casca convexa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da uma imagem podemos aplicar técnicas de segmentação baseadas em sobreposição de retângulos e aproximações de contornos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/formas.jpeg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(imagem.shape)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_gray = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "imagem_bordas = cv2.Canny(imagem_gray, 1, 100)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Contornos Ordenados\")\n",
    "plt.imshow(imagem_bordas, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aproximação por retângulo delimitador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contornos, _ = cv2.findContours(imagem_bordas, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "image_retangulo_delimitador = imagem.copy()\n",
    "\n",
    "for contorno in contornos:\n",
    "    (x, y, w, h) = cv2.boundingRect(contorno)\n",
    "    cv2.rectangle(image_retangulo_delimitador, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Aproximação por retângulo delimitador.\")\n",
    "plt.imshow(image_retangulo_delimitador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando as coordenadas do retângulo delimitador para extrar a região de interesse em arquivo externo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "for contorno in contornos:\n",
    "    area = cv2.contourArea(contorno)\n",
    "    if area > 1000:\n",
    "        (x, y, w, h) = cv2.boundingRect(contorno)\n",
    "        cv2.rectangle(image_retangulo_delimitador, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
    "        roi = imagem[y:y+h, x:x+w]\n",
    "        roi = cv2.cvtColor(roi, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(str(i) + \".png\", roi)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aproximação por polígonos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_contorno_poligonos = imagem.copy()\n",
    "\n",
    "for contorno in contornos:\n",
    "    similaridade = 0.03 * cv2.arcLength(contorno, True)\n",
    "    aproximacao_poligono = cv2.approxPolyDP(contorno, similaridade, True)\n",
    "    cv2.drawContours(imagem_contorno_poligonos, [aproximacao_poligono], 0, (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Aproximação por polígonos.\")\n",
    "plt.imshow(imagem_contorno_poligonos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_contorno_poligonos = imagem.copy()\n",
    "\n",
    "for contorno in contornos:\n",
    "    similaridade = 0.0003 * cv2.arcLength(contorno, True)\n",
    "    aproximacao_poligono = cv2.approxPolyDP(contorno, similaridade, True)\n",
    "    cv2.drawContours(imagem_contorno_poligonos, [aproximacao_poligono], 0, (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Aproximação por polígonos\")\n",
    "plt.imshow(imagem_contorno_poligonos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aproximação por casca convexa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_casca_convexa = imagem.copy()\n",
    "\n",
    "for contorno in contornos:\n",
    "    imagem_convex_hull = cv2.convexHull(contorno)\n",
    "    cv2.drawContours(imagem_casca_convexa, [imagem_convex_hull], 0, (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Aproximação por casca convexa\")\n",
    "plt.imshow(imagem_casca_convexa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Especial: Óleo no Nordeste\n",
    "\n",
    "Identificando manchas de óleo utilizando detector de bordas e limpeza de ruídos com limiarização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread(\"imagens/oleo_no_nordeste.jpeg\")\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Óleo no Nordeste\")\n",
    "plt.imshow(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_gray = cv2.cvtColor(imagem, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Óleo no Nordeste gray\")\n",
    "plt.imshow(imagem_gray, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_bordas = cv2.Canny(imagem_gray, 1, 100)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Contornos sem pré-processamento\")\n",
    "plt.imshow(imagem_bordas, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_suav_padrao = cv2.GaussianBlur(imagem_gray, (19,19), 0)\n",
    "ret, imagem_limiarizada = cv2.threshold(imagem_suav_padrao, 95, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Limiarização para zero\")\n",
    "plt.imshow(imagem_limiarizada, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_bordas = cv2.Canny(imagem_limiarizada, 1, 100)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title(\"Contornos\")\n",
    "plt.imshow(imagem_bordas, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contornos_formas, hierarchy = cv2.findContours(imagem_bordas, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(\"Contornos encontrados \"+str(len(contornos_formas)))\n",
    "\n",
    "imagem_contornos = imagem.copy()\n",
    "\n",
    "cv2.drawContours(imagem_contornos, contornos_formas, -1, (0,255,0), 2)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Contornos\")\n",
    "plt.imshow(imagem_contornos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contorno in contornos_formas:\n",
    "    print(cv2.contourArea(contorno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contornos_padronizados = []\n",
    "\n",
    "for contorno in contornos_formas:\n",
    "    if cv2.contourArea(contorno) > 10000:\n",
    "        contornos_padronizados.append(contorno)\n",
    "    \n",
    "len(contornos_formas), len(contornos_padronizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_contornos = imagem.copy()\n",
    "cv2.drawContours(imagem_contornos, contornos_padronizados, -1, (0,255,0), 2)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Contornos\")\n",
    "plt.imshow(imagem_contornos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
